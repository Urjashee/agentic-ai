{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Deep Research\n",
    "\n",
    "One of the classic cross-business Agentic use cases! This is huge."
   ],
   "id": "84bdcbcdf0eaa68a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:51:14.537781Z",
     "start_time": "2025-08-23T15:51:10.255934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from agents import Agent, WebSearchTool, trace, Runner, gen_trace_id, function_tool\n",
    "from agents.model_settings import ModelSettings\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "import sendgrid\n",
    "import os\n",
    "from sendgrid.helpers.mail import Mail, Email, To, Content\n",
    "from typing import Dict\n",
    "from IPython.display import display, Markdown\n",
    "from duckduckgo_search import DDGS"
   ],
   "id": "992f1be37509dda3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:51:15.194791Z",
     "start_time": "2025-08-23T15:51:15.179244Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv(override=True)",
   "id": "419e8290c5769f1c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:51:16.012058Z",
     "start_time": "2025-08-23T15:51:16.004214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INSTRUCTIONS = \"You are a research assistant. Given a search term, you search the web for that term and \\\n",
    "produce a concise summary of the results. The summary must 2-3 paragraphs and less than 300 \\\n",
    "words. Capture the main points. Write succinctly, no need to have complete sentences or good \\\n",
    "grammar. This will be consumed by someone synthesizing a report, so it's vital you capture the \\\n",
    "essence and ignore any fluff. Do not include any additional commentary other than the summary itself.\""
   ],
   "id": "e339c799e53e749b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:51:16.817534Z",
     "start_time": "2025-08-23T15:51:16.808684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "search_agent = Agent(\n",
    "    name=\"Search agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[WebSearchTool(search_context_size=\"low\")],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")"
   ],
   "id": "19bc42f1cdd4debc",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:51:20.037729Z",
     "start_time": "2025-08-23T15:51:20.031350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import os\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "print(os.getenv(\"OPENAI_BASE_URL\"))"
   ],
   "id": "38cc3abbd42349bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:51:31.253754Z",
     "start_time": "2025-08-23T15:51:21.137010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "message = \"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "with trace(\"Search\"):\n",
    "    result = await Runner.run(search_agent, message)\n",
    "\n",
    "display(Markdown(result.final_output))"
   ],
   "id": "7391d89d0e34dfe9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "As of August 2025, several AI agent frameworks have emerged, each offering unique capabilities for developing intelligent, autonomous systems:\n\n- **LangChain**: A modular framework for building applications powered by large language models (LLMs). It provides tools for chaining prompts, models, memory, and external tools, facilitating the creation of complex workflows. ([medium.com](https://medium.com/%40elisowski/top-ai-agent-frameworks-in-2025-9bcedab2e239?utm_source=openai))\n\n- **LangGraph**: An extension of LangChain, LangGraph focuses on stateful, graph-based agent systems. It allows for explicit control over agent workflows, supporting branching and debugging of complex behaviors. ([radarmagazine.com](https://www.radarmagazine.com/top-5-ai-agent-frameworks-it-executives-should-be-watching-in-2025/?utm_source=openai))\n\n- **CrewAI**: This framework adopts a role-based collaboration approach, enabling the creation of specialized agents that work together on complex projects. It features dynamic task planning and real-time performance monitoring. ([linkedin.com](https://www.linkedin.com/pulse/ai-agent-frameworks-june-2025-comprehensive-overview-chadi-abi-fadel-wcu5c?utm_source=openai))\n\n- **AutoGen**: Developed by Microsoft, AutoGen specializes in orchestrating multiple AI agents to form autonomous, event-driven systems capable of handling complex, multi-agent tasks seamlessly. ([linkedin.com](https://www.linkedin.com/pulse/ai-agent-frameworks-june-2025-comprehensive-overview-chadi-abi-fadel-wcu5c?utm_source=openai))\n\n- **SuperAGI**: A production-grade, open-source agent framework designed for autonomy. SuperAGI includes scheduling, execution monitoring, performance dashboards, and persistent agent memory. ([medium.com](https://medium.com/%40rajadityasatellite/2025-is-the-year-of-ai-agent-frameworks-cb24e3f9ffc7?utm_source=openai))\n\n- **Eliza**: A Web3-friendly AI agent operating system that integrates seamlessly with blockchain applications, allowing for the deployment of decentralized AI agents. ([arxiv.org](https://arxiv.org/abs/2501.06781?utm_source=openai))\n\n- **Agent Lightning**: A flexible and extensible framework that enables reinforcement learning-based training of LLMs for any AI agent, facilitating complex interaction logic and multi-agent scenarios. ([arxiv.org](https://arxiv.org/abs/2508.03680?utm_source=openai))\n\n- **AutoAgent**: A fully-automated, zero-code framework for LLM agents, enabling users to create and deploy agents through natural language alone, making AI agent development accessible to non-technical users. ([arxiv.org](https://arxiv.org/abs/2502.05957?utm_source=openai))\n\nThese frameworks represent the forefront of AI agent development, each catering to different needs and applications in the rapidly evolving field of artificial intelligence. "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:39:31.726747Z",
     "start_time": "2025-08-23T15:39:31.716931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# os.environ[\"OPENAI_BASE_URL\"] = \"http://localhost:11434/v1\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"ollama\"\n",
    "# os.environ[\"OPENAI_API_TYPE\"] = \"chat\""
   ],
   "id": "bdf0f9863da4f4e0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:39:36.406134Z",
     "start_time": "2025-08-23T15:39:36.398151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "# print(os.getenv(\"OPENAI_BASE_URL\"))"
   ],
   "id": "510d6a3197b2e1ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama\n",
      "http://localhost:11434/v1\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:39:59.619094Z",
     "start_time": "2025-08-23T15:39:59.607944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# @function_tool\n",
    "# def duckduckgo_search(query: str, max_results: int = 3):\n",
    "#     \"\"\"\n",
    "#     Search the web using DuckDuckGo and return the results as a Markdown list\n",
    "#     with titles linked to their URLs, and short snippets under each title.\n",
    "#     \"\"\"\n",
    "#     with DDGS() as ddgs:\n",
    "#         results = ddgs.text(query, max_results=max_results)\n",
    "#         return \"\\n\".join(\n",
    "#             f\"- **[{r['title']}]({r['href']})**\\n  {r['body']}\"\n",
    "#             for r in results\n",
    "#         )"
   ],
   "id": "613523514757e702",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:40:17.621960Z",
     "start_time": "2025-08-23T15:40:17.613275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# search_agent = Agent(\n",
    "#     name=\"Search agent\",\n",
    "#     instructions=INSTRUCTIONS,\n",
    "#     tools=[duckduckgo_search],\n",
    "#     model=\"mistral:latest\",\n",
    "#     model_settings=ModelSettings(tool_choice=\"required\"),\n",
    "# )"
   ],
   "id": "e9191aca7642f9b5",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T15:50:24.347485Z",
     "start_time": "2025-08-23T15:50:23.463671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# message = \"Latest AI Agent frameworks in 2025\"\n",
    "#\n",
    "# result = await Runner.run(search_agent, message)\n",
    "#\n",
    "# display(Markdown(result.final_output))"
   ],
   "id": "5ddf25be133f7ceb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error getting response: 404 page not found. (request_id: None)\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "404 page not found",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNotFoundError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m message = \u001B[33m\"\u001B[39m\u001B[33mLatest AI Agent frameworks in 2025\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m result = \u001B[38;5;28;01mawait\u001B[39;00m Runner.run(search_agent, message)\n\u001B[32m      5\u001B[39m display(Markdown(result.final_output))\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\agentic_ai\\projects\\agents_blank\\.venv\\Lib\\site-packages\\agents\\run.py:237\u001B[39m, in \u001B[36mRunner.run\u001B[39m\u001B[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, session)\u001B[39m\n\u001B[32m    210\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Run a workflow starting at the given agent. The agent will run in a loop until a final\u001B[39;00m\n\u001B[32m    211\u001B[39m \u001B[33;03moutput is generated. The loop runs like so:\u001B[39;00m\n\u001B[32m    212\u001B[39m \u001B[33;03m1. The agent is invoked with the given input.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    234\u001B[39m \u001B[33;03m    agent. Agents may perform handoffs, so we don't know the specific type of the output.\u001B[39;00m\n\u001B[32m    235\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    236\u001B[39m runner = DEFAULT_AGENT_RUNNER\n\u001B[32m--> \u001B[39m\u001B[32m237\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m runner.run(\n\u001B[32m    238\u001B[39m     starting_agent,\n\u001B[32m    239\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m    240\u001B[39m     context=context,\n\u001B[32m    241\u001B[39m     max_turns=max_turns,\n\u001B[32m    242\u001B[39m     hooks=hooks,\n\u001B[32m    243\u001B[39m     run_config=run_config,\n\u001B[32m    244\u001B[39m     previous_response_id=previous_response_id,\n\u001B[32m    245\u001B[39m     session=session,\n\u001B[32m    246\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\agentic_ai\\projects\\agents_blank\\.venv\\Lib\\site-packages\\agents\\run.py:443\u001B[39m, in \u001B[36mAgentRunner.run\u001B[39m\u001B[34m(self, starting_agent, input, **kwargs)\u001B[39m\n\u001B[32m    438\u001B[39m logger.debug(\n\u001B[32m    439\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mRunning agent \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_agent.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m (turn \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_turn\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m)\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    440\u001B[39m )\n\u001B[32m    442\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m current_turn == \u001B[32m1\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m443\u001B[39m     input_guardrail_results, turn_result = \u001B[38;5;28;01mawait\u001B[39;00m asyncio.gather(\n\u001B[32m    444\u001B[39m         \u001B[38;5;28mself\u001B[39m._run_input_guardrails(\n\u001B[32m    445\u001B[39m             starting_agent,\n\u001B[32m    446\u001B[39m             starting_agent.input_guardrails\n\u001B[32m    447\u001B[39m             + (run_config.input_guardrails \u001B[38;5;129;01mor\u001B[39;00m []),\n\u001B[32m    448\u001B[39m             _copy_str_or_list(prepared_input),\n\u001B[32m    449\u001B[39m             context_wrapper,\n\u001B[32m    450\u001B[39m         ),\n\u001B[32m    451\u001B[39m         \u001B[38;5;28mself\u001B[39m._run_single_turn(\n\u001B[32m    452\u001B[39m             agent=current_agent,\n\u001B[32m    453\u001B[39m             all_tools=all_tools,\n\u001B[32m    454\u001B[39m             original_input=original_input,\n\u001B[32m    455\u001B[39m             generated_items=generated_items,\n\u001B[32m    456\u001B[39m             hooks=hooks,\n\u001B[32m    457\u001B[39m             context_wrapper=context_wrapper,\n\u001B[32m    458\u001B[39m             run_config=run_config,\n\u001B[32m    459\u001B[39m             should_run_agent_start_hooks=should_run_agent_start_hooks,\n\u001B[32m    460\u001B[39m             tool_use_tracker=tool_use_tracker,\n\u001B[32m    461\u001B[39m             previous_response_id=previous_response_id,\n\u001B[32m    462\u001B[39m         ),\n\u001B[32m    463\u001B[39m     )\n\u001B[32m    464\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    465\u001B[39m     turn_result = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._run_single_turn(\n\u001B[32m    466\u001B[39m         agent=current_agent,\n\u001B[32m    467\u001B[39m         all_tools=all_tools,\n\u001B[32m   (...)\u001B[39m\u001B[32m    475\u001B[39m         previous_response_id=previous_response_id,\n\u001B[32m    476\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\agentic_ai\\projects\\agents_blank\\.venv\\Lib\\site-packages\\agents\\run.py:1036\u001B[39m, in \u001B[36mAgentRunner._run_single_turn\u001B[39m\u001B[34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001B[39m\n\u001B[32m   1033\u001B[39m \u001B[38;5;28minput\u001B[39m = ItemHelpers.input_to_new_input_list(original_input)\n\u001B[32m   1034\u001B[39m \u001B[38;5;28minput\u001B[39m.extend([generated_item.to_input_item() \u001B[38;5;28;01mfor\u001B[39;00m generated_item \u001B[38;5;129;01min\u001B[39;00m generated_items])\n\u001B[32m-> \u001B[39m\u001B[32m1036\u001B[39m new_response = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mcls\u001B[39m._get_new_response(\n\u001B[32m   1037\u001B[39m     agent,\n\u001B[32m   1038\u001B[39m     system_prompt,\n\u001B[32m   1039\u001B[39m     \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   1040\u001B[39m     output_schema,\n\u001B[32m   1041\u001B[39m     all_tools,\n\u001B[32m   1042\u001B[39m     handoffs,\n\u001B[32m   1043\u001B[39m     context_wrapper,\n\u001B[32m   1044\u001B[39m     run_config,\n\u001B[32m   1045\u001B[39m     tool_use_tracker,\n\u001B[32m   1046\u001B[39m     previous_response_id,\n\u001B[32m   1047\u001B[39m     prompt_config,\n\u001B[32m   1048\u001B[39m )\n\u001B[32m   1050\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mcls\u001B[39m._get_single_step_result_from_response(\n\u001B[32m   1051\u001B[39m     agent=agent,\n\u001B[32m   1052\u001B[39m     original_input=original_input,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1061\u001B[39m     tool_use_tracker=tool_use_tracker,\n\u001B[32m   1062\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\agentic_ai\\projects\\agents_blank\\.venv\\Lib\\site-packages\\agents\\run.py:1256\u001B[39m, in \u001B[36mAgentRunner._get_new_response\u001B[39m\u001B[34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id, prompt_config)\u001B[39m\n\u001B[32m   1253\u001B[39m model_settings = agent.model_settings.resolve(run_config.model_settings)\n\u001B[32m   1254\u001B[39m model_settings = RunImpl.maybe_reset_tool_choice(agent, tool_use_tracker, model_settings)\n\u001B[32m-> \u001B[39m\u001B[32m1256\u001B[39m new_response = \u001B[38;5;28;01mawait\u001B[39;00m model.get_response(\n\u001B[32m   1257\u001B[39m     system_instructions=filtered.instructions,\n\u001B[32m   1258\u001B[39m     \u001B[38;5;28minput\u001B[39m=filtered.input,\n\u001B[32m   1259\u001B[39m     model_settings=model_settings,\n\u001B[32m   1260\u001B[39m     tools=all_tools,\n\u001B[32m   1261\u001B[39m     output_schema=output_schema,\n\u001B[32m   1262\u001B[39m     handoffs=handoffs,\n\u001B[32m   1263\u001B[39m     tracing=get_model_tracing_impl(\n\u001B[32m   1264\u001B[39m         run_config.tracing_disabled, run_config.trace_include_sensitive_data\n\u001B[32m   1265\u001B[39m     ),\n\u001B[32m   1266\u001B[39m     previous_response_id=previous_response_id,\n\u001B[32m   1267\u001B[39m     prompt=prompt_config,\n\u001B[32m   1268\u001B[39m )\n\u001B[32m   1270\u001B[39m context_wrapper.usage.add(new_response.usage)\n\u001B[32m   1272\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m new_response\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\agentic_ai\\projects\\agents_blank\\.venv\\Lib\\site-packages\\agents\\models\\openai_responses.py:83\u001B[39m, in \u001B[36mOpenAIResponsesModel.get_response\u001B[39m\u001B[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id, prompt)\u001B[39m\n\u001B[32m     81\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m response_span(disabled=tracing.is_disabled()) \u001B[38;5;28;01mas\u001B[39;00m span_response:\n\u001B[32m     82\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m         response = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._fetch_response(\n\u001B[32m     84\u001B[39m             system_instructions,\n\u001B[32m     85\u001B[39m             \u001B[38;5;28minput\u001B[39m,\n\u001B[32m     86\u001B[39m             model_settings,\n\u001B[32m     87\u001B[39m             tools,\n\u001B[32m     88\u001B[39m             output_schema,\n\u001B[32m     89\u001B[39m             handoffs,\n\u001B[32m     90\u001B[39m             previous_response_id,\n\u001B[32m     91\u001B[39m             stream=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m     92\u001B[39m             prompt=prompt,\n\u001B[32m     93\u001B[39m         )\n\u001B[32m     95\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m _debug.DONT_LOG_MODEL_DATA:\n\u001B[32m     96\u001B[39m             logger.debug(\u001B[33m\"\u001B[39m\u001B[33mLLM responded\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\agentic_ai\\projects\\agents_blank\\.venv\\Lib\\site-packages\\agents\\models\\openai_responses.py:279\u001B[39m, in \u001B[36mOpenAIResponsesModel._fetch_response\u001B[39m\u001B[34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, previous_response_id, stream, prompt)\u001B[39m\n\u001B[32m    276\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    277\u001B[39m         response_format = {\u001B[33m\"\u001B[39m\u001B[33mverbosity\u001B[39m\u001B[33m\"\u001B[39m: model_settings.verbosity}\n\u001B[32m--> \u001B[39m\u001B[32m279\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._client.responses.create(\n\u001B[32m    280\u001B[39m     previous_response_id=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(previous_response_id),\n\u001B[32m    281\u001B[39m     instructions=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(system_instructions),\n\u001B[32m    282\u001B[39m     model=\u001B[38;5;28mself\u001B[39m.model,\n\u001B[32m    283\u001B[39m     \u001B[38;5;28minput\u001B[39m=list_input,\n\u001B[32m    284\u001B[39m     include=include,\n\u001B[32m    285\u001B[39m     tools=converted_tools.tools,\n\u001B[32m    286\u001B[39m     prompt=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(prompt),\n\u001B[32m    287\u001B[39m     temperature=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.temperature),\n\u001B[32m    288\u001B[39m     top_p=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.top_p),\n\u001B[32m    289\u001B[39m     truncation=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.truncation),\n\u001B[32m    290\u001B[39m     max_output_tokens=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.max_tokens),\n\u001B[32m    291\u001B[39m     tool_choice=tool_choice,\n\u001B[32m    292\u001B[39m     parallel_tool_calls=parallel_tool_calls,\n\u001B[32m    293\u001B[39m     stream=stream,\n\u001B[32m    294\u001B[39m     extra_headers={**_HEADERS, **(model_settings.extra_headers \u001B[38;5;129;01mor\u001B[39;00m {})},\n\u001B[32m    295\u001B[39m     extra_query=model_settings.extra_query,\n\u001B[32m    296\u001B[39m     extra_body=model_settings.extra_body,\n\u001B[32m    297\u001B[39m     text=response_format,\n\u001B[32m    298\u001B[39m     store=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.store),\n\u001B[32m    299\u001B[39m     reasoning=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.reasoning),\n\u001B[32m    300\u001B[39m     metadata=\u001B[38;5;28mself\u001B[39m._non_null_or_not_given(model_settings.metadata),\n\u001B[32m    301\u001B[39m     **extra_args,\n\u001B[32m    302\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\agentic_ai\\projects\\agents_blank\\.venv\\Lib\\site-packages\\openai\\resources\\responses\\responses.py:2155\u001B[39m, in \u001B[36mAsyncResponses.create\u001B[39m\u001B[34m(self, background, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001B[39m\n\u001B[32m   2119\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate\u001B[39m(\n\u001B[32m   2120\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   2121\u001B[39m     *,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2153\u001B[39m     timeout: \u001B[38;5;28mfloat\u001B[39m | httpx.Timeout | \u001B[38;5;28;01mNone\u001B[39;00m | NotGiven = NOT_GIVEN,\n\u001B[32m   2154\u001B[39m ) -> Response | AsyncStream[ResponseStreamEvent]:\n\u001B[32m-> \u001B[39m\u001B[32m2155\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m._post(\n\u001B[32m   2156\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m/responses\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   2157\u001B[39m         body=\u001B[38;5;28;01mawait\u001B[39;00m async_maybe_transform(\n\u001B[32m   2158\u001B[39m             {\n\u001B[32m   2159\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mbackground\u001B[39m\u001B[33m\"\u001B[39m: background,\n\u001B[32m   2160\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33minclude\u001B[39m\u001B[33m\"\u001B[39m: include,\n\u001B[32m   2161\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33minput\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28minput\u001B[39m,\n\u001B[32m   2162\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33minstructions\u001B[39m\u001B[33m\"\u001B[39m: instructions,\n\u001B[32m   2163\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmax_output_tokens\u001B[39m\u001B[33m\"\u001B[39m: max_output_tokens,\n\u001B[32m   2164\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmax_tool_calls\u001B[39m\u001B[33m\"\u001B[39m: max_tool_calls,\n\u001B[32m   2165\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m\"\u001B[39m: metadata,\n\u001B[32m   2166\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: model,\n\u001B[32m   2167\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mparallel_tool_calls\u001B[39m\u001B[33m\"\u001B[39m: parallel_tool_calls,\n\u001B[32m   2168\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprevious_response_id\u001B[39m\u001B[33m\"\u001B[39m: previous_response_id,\n\u001B[32m   2169\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprompt\u001B[39m\u001B[33m\"\u001B[39m: prompt,\n\u001B[32m   2170\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mprompt_cache_key\u001B[39m\u001B[33m\"\u001B[39m: prompt_cache_key,\n\u001B[32m   2171\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mreasoning\u001B[39m\u001B[33m\"\u001B[39m: reasoning,\n\u001B[32m   2172\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33msafety_identifier\u001B[39m\u001B[33m\"\u001B[39m: safety_identifier,\n\u001B[32m   2173\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mservice_tier\u001B[39m\u001B[33m\"\u001B[39m: service_tier,\n\u001B[32m   2174\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstore\u001B[39m\u001B[33m\"\u001B[39m: store,\n\u001B[32m   2175\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m: stream,\n\u001B[32m   2176\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mstream_options\u001B[39m\u001B[33m\"\u001B[39m: stream_options,\n\u001B[32m   2177\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtemperature\u001B[39m\u001B[33m\"\u001B[39m: temperature,\n\u001B[32m   2178\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtext\u001B[39m\u001B[33m\"\u001B[39m: text,\n\u001B[32m   2179\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtool_choice\u001B[39m\u001B[33m\"\u001B[39m: tool_choice,\n\u001B[32m   2180\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtools\u001B[39m\u001B[33m\"\u001B[39m: tools,\n\u001B[32m   2181\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtop_logprobs\u001B[39m\u001B[33m\"\u001B[39m: top_logprobs,\n\u001B[32m   2182\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtop_p\u001B[39m\u001B[33m\"\u001B[39m: top_p,\n\u001B[32m   2183\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33mtruncation\u001B[39m\u001B[33m\"\u001B[39m: truncation,\n\u001B[32m   2184\u001B[39m                 \u001B[33m\"\u001B[39m\u001B[33muser\u001B[39m\u001B[33m\"\u001B[39m: user,\n\u001B[32m   2185\u001B[39m             },\n\u001B[32m   2186\u001B[39m             response_create_params.ResponseCreateParamsStreaming\n\u001B[32m   2187\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m stream\n\u001B[32m   2188\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m response_create_params.ResponseCreateParamsNonStreaming,\n\u001B[32m   2189\u001B[39m         ),\n\u001B[32m   2190\u001B[39m         options=make_request_options(\n\u001B[32m   2191\u001B[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001B[32m   2192\u001B[39m         ),\n\u001B[32m   2193\u001B[39m         cast_to=Response,\n\u001B[32m   2194\u001B[39m         stream=stream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m   2195\u001B[39m         stream_cls=AsyncStream[ResponseStreamEvent],\n\u001B[32m   2196\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\agentic_ai\\projects\\agents_blank\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1794\u001B[39m, in \u001B[36mAsyncAPIClient.post\u001B[39m\u001B[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1780\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpost\u001B[39m(\n\u001B[32m   1781\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   1782\u001B[39m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1789\u001B[39m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_AsyncStreamT] | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   1790\u001B[39m ) -> ResponseT | _AsyncStreamT:\n\u001B[32m   1791\u001B[39m     opts = FinalRequestOptions.construct(\n\u001B[32m   1792\u001B[39m         method=\u001B[33m\"\u001B[39m\u001B[33mpost\u001B[39m\u001B[33m\"\u001B[39m, url=path, json_data=body, files=\u001B[38;5;28;01mawait\u001B[39;00m async_to_httpx_files(files), **options\n\u001B[32m   1793\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1794\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mE:\\agentic_ai\\projects\\agents_blank\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1594\u001B[39m, in \u001B[36mAsyncAPIClient.request\u001B[39m\u001B[34m(self, cast_to, options, stream, stream_cls)\u001B[39m\n\u001B[32m   1591\u001B[39m             \u001B[38;5;28;01mawait\u001B[39;00m err.response.aread()\n\u001B[32m   1593\u001B[39m         log.debug(\u001B[33m\"\u001B[39m\u001B[33mRe-raising status error\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1594\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._make_status_error_from_response(err.response) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1596\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1598\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mcould not resolve response (should never happen)\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[31mNotFoundError\u001B[39m: 404 page not found"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:12:27.330370Z",
     "start_time": "2025-08-23T16:12:27.317486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# See note above about cost of WebSearchTool\n",
    "\n",
    "HOW_MANY_SEARCHES = 3\n",
    "\n",
    "INSTRUCTIONS = f\"You are a helpful research assistant. Given a query, come up with a set of web searches \\\n",
    "to perform to best answer the query. Output {HOW_MANY_SEARCHES} terms to query for.\"\n",
    "\n",
    "# Use Pydantic to define the Schema of our response - this is known as \"Structured Outputs\"\n",
    "# With massive thanks to student Wes C. for discovering and fixing a nasty bug with this!\n",
    "\n",
    "class WebSearchItem(BaseModel):\n",
    "    reason: str = Field(description=\"Your reasoning for why this search is important to the query.\")\n",
    "\n",
    "    query: str = Field(description=\"The search term to use for the web search.\")\n",
    "\n",
    "\n",
    "class WebSearchPlan(BaseModel):\n",
    "    searches: list[WebSearchItem] = Field(description=\"A list of web searches to perform to best answer the query.\")\n",
    "\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"PlannerAgent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    output_type=WebSearchPlan,\n",
    ")"
   ],
   "id": "299f75beee9f81fe",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:16:22.195311Z",
     "start_time": "2025-08-23T16:16:18.715433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "message = \"Latest AI Agent frameworks in 2025\"\n",
    "\n",
    "with trace(\"Search\"):\n",
    "    result = await Runner.run(planner_agent, message)\n",
    "    print(result.final_output)"
   ],
   "id": "a1e265fb1616e000",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searches=[WebSearchItem(reason='To find updated information about AI agent frameworks released or popular in 2025.', query='latest AI agent frameworks 2025'), WebSearchItem(reason='To identify trends and advancements in AI agents for 2025.', query='AI agent technologies 2025'), WebSearchItem(reason='To see comparisons or lists of top AI agent frameworks in the current year.', query='best AI agent frameworks 2025')]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:18:31.530559Z",
     "start_time": "2025-08-23T16:18:31.521487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@function_tool\n",
    "def send_email(subject: str, html_body: str) -> Dict[str, str]:\n",
    "    \"\"\" Send out an email with the given subject and HTML body \"\"\"\n",
    "    sg = sendgrid.SendGridAPIClient(api_key=os.environ.get('SENDGRID_API_KEY'))\n",
    "    from_email = Email(\"info@nesoftech.com\") # Change this to your verified email\n",
    "    to_email = To(\"urjashee09@gmail.com\") # Change this to your email\n",
    "    content = Content(\"text/html\", html_body)\n",
    "    mail = Mail(from_email, to_email, subject, content).get()\n",
    "    response = sg.client.mail.send.post(request_body=mail)\n",
    "    return {\"status\": \"success\"}"
   ],
   "id": "8e044ca7002b6cf0",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:18:50.732770Z",
     "start_time": "2025-08-23T16:18:50.724649Z"
    }
   },
   "cell_type": "code",
   "source": "send_email",
   "id": "2a0fca2d5b9c414b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionTool(name='send_email', description='Send out an email with the given subject and HTML body', params_json_schema={'properties': {'subject': {'title': 'Subject', 'type': 'string'}, 'html_body': {'title': 'Html Body', 'type': 'string'}}, 'required': ['subject', 'html_body'], 'title': 'send_email_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000001FF90BE8360>, strict_json_schema=True, is_enabled=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:20:57.036200Z",
     "start_time": "2025-08-23T16:20:57.029516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INSTRUCTIONS = \"\"\"You are able to send a nicely formatted HTML email based on a detailed report.\n",
    "You will be provided with a detailed report. You should use your tool to send one email, providing the\n",
    "report converted into clean, well presented HTML with an appropriate subject line.\"\"\"\n",
    "\n",
    "email_agent = Agent(\n",
    "    name=\"Email agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    tools=[send_email],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ],
   "id": "2eac4670f75e9662",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:21:30.172683Z",
     "start_time": "2025-08-23T16:21:30.165636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INSTRUCTIONS = (\n",
    "    \"You are a senior researcher tasked with writing a cohesive report for a research query. \"\n",
    "    \"You will be provided with the original query, and some initial research done by a research assistant.\\n\"\n",
    "    \"You should first come up with an outline for the report that describes the structure and \"\n",
    "    \"flow of the report. Then, generate the report and return that as your final output.\\n\"\n",
    "    \"The final output should be in markdown format, and it should be lengthy and detailed. Aim \"\n",
    "    \"for 5-10 pages of content, at least 1000 words.\"\n",
    ")"
   ],
   "id": "702765c78ea191ea",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:23:07.765346Z",
     "start_time": "2025-08-23T16:23:07.755923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReportData(BaseModel):\n",
    "    short_summary: str = Field(description=\"A short 2-3 sentence summary of the findings.\")\n",
    "\n",
    "    markdown_report: str = Field(description=\"The final report\")\n",
    "\n",
    "    follow_up_questions: list[str] = Field(description=\"Suggested topics to research further\")\n",
    "\n",
    "\n",
    "writer_agent = Agent(\n",
    "    name=\"WriterAgent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    output_type=ReportData,\n",
    ")"
   ],
   "id": "bb4588ce523a8530",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The next 3 functions will plan and execute the search, using planner_agent and search_agent",
   "id": "a117700d7b76291d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:24:58.790975Z",
     "start_time": "2025-08-23T16:24:58.782223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def plan_searches(query: str):\n",
    "    \"\"\" Use the planner_agent to plan which searches to run for the query \"\"\"\n",
    "    print(\"Planning searches...\")\n",
    "    result = await Runner.run(planner_agent, f\"Query: {query}\")\n",
    "    print(f\"Will perform {len(result.final_output.searches)} searches\")\n",
    "    return result.final_output\n",
    "\n",
    "async def perform_searches(search_plan: WebSearchPlan):\n",
    "    \"\"\" Call search() for each item in the search plan \"\"\"\n",
    "    print(\"Searching...\")\n",
    "    tasks = [asyncio.create_task(search(item)) for item in search_plan.searches]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    print(\"Finished searching\")\n",
    "    return results\n",
    "\n",
    "async def search(item: WebSearchItem):\n",
    "    \"\"\" Use the search agent to run a web search for each item in the search plan \"\"\"\n",
    "    input = f\"Search term: {item.query}\\nReason for searching: {item.reason}\"\n",
    "    result = await Runner.run(search_agent, input)\n",
    "    return result.final_output"
   ],
   "id": "e46301cbdd71273e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The next 2 functions write a report and email it",
   "id": "4a475c4386b9db44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:25:14.094621Z",
     "start_time": "2025-08-23T16:25:14.086108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def write_report(query: str, search_results: list[str]):\n",
    "    \"\"\" Use the writer agent to write a report based on the search results\"\"\"\n",
    "    print(\"Thinking about report...\")\n",
    "    input = f\"Original query: {query}\\nSummarized search results: {search_results}\"\n",
    "    result = await Runner.run(writer_agent, input)\n",
    "    print(\"Finished writing report\")\n",
    "    return result.final_output\n",
    "\n",
    "async def send_email(report: ReportData):\n",
    "    \"\"\" Use the email agent to send an email with the report \"\"\"\n",
    "    print(\"Writing email...\")\n",
    "    result = await Runner.run(email_agent, report.markdown_report)\n",
    "    print(\"Email sent\")\n",
    "    return report"
   ],
   "id": "1a6033664a1e08b0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T16:36:46.437315Z",
     "start_time": "2025-08-23T16:35:18.264034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query =\"What stocks to buy in India on August, 2025\"\n",
    "\n",
    "with trace(\"Research trace\"):\n",
    "    print(\"Starting research...\")\n",
    "    search_plan = await plan_searches(query)\n",
    "    search_results = await perform_searches(search_plan)\n",
    "    report = await write_report(query, search_results)\n",
    "    await send_email(report)\n",
    "    print(\"Hooray!\")\n",
    "\n",
    "\n"
   ],
   "id": "c43a41ec58718dd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting research...\n",
      "Planning searches...\n",
      "Will perform 3 searches\n",
      "Searching...\n",
      "Finished searching\n",
      "Thinking about report...\n",
      "Finished writing report\n",
      "Writing email...\n",
      "Email sent\n",
      "Hooray!\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d0f2310dafebc79f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
