{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### And now - Week 3 Day 3\n",
    "\n",
    "## AutoGen Core\n",
    "\n",
    "Something a little different.\n",
    "\n",
    "This is agnostic to the underlying Agent framework\n",
    "\n",
    "You can use AutoGen AgentChat, or you can use something else; it's an Agent interaction framework.\n",
    "\n",
    "From that point of view, it's positioned similarly to LangGraph.\n",
    "\n",
    "### The fundamental principle\n",
    "\n",
    "Autogen Core decouples an agent's logic from how messages are delivered.\n",
    "The framework provides a communication infrastructure, along with agent lifecycle, and the agents are responsible for their own work.\n",
    "\n",
    "The communication infrastructure is called a Runtime.\n",
    "\n",
    "There are 2 types: **Standalone** and **Distributed**.\n",
    "\n",
    "Today we will use a standalone runtime: the **SingleThreadedAgentRuntime**, a local embedded agent runtime implementation.\n",
    "\n",
    "Tomorrow we'll briefly look at a Distributed runtime.\n"
   ],
   "id": "f3400ba3820fbe81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:44:22.239789Z",
     "start_time": "2025-08-31T15:44:19.934597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from autogen_core import AgentId, MessageContext, RoutedAgent, message_handler\n",
    "from autogen_core import SingleThreadedAgentRuntime\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv"
   ],
   "id": "506ed133df1dacfc",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:44:22.884224Z",
     "start_time": "2025-08-31T15:44:22.862001Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv(override=True)",
   "id": "11ba6cb1428e5587",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### First we define our Message object\n",
    "\n",
    "Whatever structure we want for messages in our Agent framework."
   ],
   "id": "6df8ac915f8f5616"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:44:27.227121Z",
     "start_time": "2025-08-31T15:44:27.221264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's have a simple one!\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n"
   ],
   "id": "a56cae05f639a4d2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "### Now we define our Agent\n",
    "\n",
    "A subclass of RoutedAgent.\n",
    "\n",
    "Every Agent has an **Agent ID** which has 2 components:\n",
    "`agent.id.type` describes the kind of agent it is\n",
    "`agent.id.key` gives it its unique identifier\n",
    "\n",
    "Any method with the `@message_handler` decorated will have the opportunity to receive messages.\n"
   ],
   "id": "8e3056840188eedc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:49:38.231021Z",
     "start_time": "2025-08-31T11:49:38.219879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"Simple\")\n",
    "\n",
    "    @message_handler\n",
    "    async def on_my_message(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        return Message(content=f\"This is {self.id.type}-{self.id.key}. You said '{message.content}' and I disagree.\")\n"
   ],
   "id": "bb663c89d887b3e3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### OK let's create a Standalone runtime and register our agent type",
   "id": "1b913e6bb15c411c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:50:54.836737Z",
     "start_time": "2025-08-31T11:50:54.828763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())"
   ],
   "id": "5dc80f1f1c11ae38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='simple_agent')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:50:55.791805Z",
     "start_time": "2025-08-31T11:50:55.782532Z"
    }
   },
   "cell_type": "code",
   "source": "runtime.start()",
   "id": "dfb29860468580b3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:50:57.799431Z",
     "start_time": "2025-08-31T11:50:57.786766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_id = AgentId(\"simple_agent\", \"default\")\n",
    "response = await runtime.send_message(Message(\"Well hi there!\"), agent_id)\n",
    "print(\">>>\", response.content)"
   ],
   "id": "f016fc8aceb6f857",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> This is simple_agent-default. You said 'Well hi there!' and I disagree.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:50:59.339094Z",
     "start_time": "2025-08-31T11:50:59.333254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ],
   "id": "480936ca7617235d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### OK Now let's do something more interesting\n",
    "\n",
    "We'll use an AgentChat Assistant!"
   ],
   "id": "6a0671fc5b3a8bf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:54:21.205521Z",
     "start_time": "2025-08-31T11:54:21.192563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyLLMAgent(RoutedAgent):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\"LLMAgent\")\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")\n",
    "        self._delegate = AssistantAgent(\"LLMAgent\", model_client=model_client)\n",
    "    #     _delegate -> private\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        print(f\"{self.id.type} received message: {message.content}\")\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        reply = response.chat_message.content\n",
    "        print(f\"{self.id.type} responded: {reply}\")\n",
    "        return Message(content=reply)\n",
    "\n"
   ],
   "id": "1b2fe00595e8812c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:54:22.385552Z",
     "start_time": "2025-08-31T11:54:22.374201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from autogen_core import SingleThreadedAgentRuntime\n",
    "\n",
    "runtime = SingleThreadedAgentRuntime()\n",
    "await SimpleAgent.register(runtime, \"simple_agent\", lambda: SimpleAgent())\n",
    "await MyLLMAgent.register(runtime, \"LLMAgent\", lambda: MyLLMAgent())"
   ],
   "id": "6d6c54ab48307a08",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentType(type='LLMAgent')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:54:28.780644Z",
     "start_time": "2025-08-31T11:54:24.197455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runtime.start()  # Start processing messages in the background.\n",
    "response = await runtime.send_message(Message(\"Hi there!\"), AgentId(\"LLMAgent\", \"default\"))\n",
    "print(\">>>\", response.content)\n",
    "response =  await runtime.send_message(Message(response.content), AgentId(\"simple_agent\", \"default\"))\n",
    "print(\">>>\", response.content)\n",
    "response = await runtime.send_message(Message(response.content), AgentId(\"LLMAgent\", \"default\"))"
   ],
   "id": "6593df35a22d85c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMAgent received message: Hi there!\n",
      "LLMAgent responded: Hello! How can I assist you today?\n",
      ">>> Hello! How can I assist you today?\n",
      ">>> This is simple_agent-default. You said 'Hello! How can I assist you today?' and I disagree.\n",
      "LLMAgent received message: This is simple_agent-default. You said 'Hello! How can I assist you today?' and I disagree.\n",
      "LLMAgent responded: I understand that you may have a difference of opinion. How can I better assist you?\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:57:55.320388Z",
     "start_time": "2025-08-31T11:57:55.303228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ],
   "id": "682af0f05da211ec",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### OK now let's show this at work - let's have 3 agents interact!",
   "id": "de4526da946266fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:45:05.556003Z",
     "start_time": "2025-08-31T15:45:05.542304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "\n",
    "\n",
    "class Player1Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)\n",
    "\n",
    "class Player2Agent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OllamaChatCompletionClient(model=\"deepseek-r1:7b\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        text_message = TextMessage(content=message.content, source=\"user\")\n",
    "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
    "        return Message(content=response.chat_message.content)"
   ],
   "id": "b4d4983d87d52814",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:45:06.220152Z",
     "start_time": "2025-08-31T15:45:06.206547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "JUDGE = \"You are judging a game of rock, paper, scissors. The players have made these choices:\\n\"\n",
    "\n",
    "class RockPaperScissorsAgent(RoutedAgent):\n",
    "    def __init__(self, name: str) -> None:\n",
    "        super().__init__(name)\n",
    "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
    "        self._delegate = AssistantAgent(name, model_client=model_client)\n",
    "\n",
    "    @message_handler\n",
    "    async def handle_my_message_type(self, message: Message, ctx: MessageContext) -> Message:\n",
    "        instruction = \"You are playing rock, paper, scissors. Respond only with the one word, one of the following: rock, paper, or scissors.\"\n",
    "        message = Message(content=instruction)\n",
    "        inner_1 = AgentId(\"player1\", \"default\")\n",
    "        inner_2 = AgentId(\"player2\", \"default\")\n",
    "        response1 = await self.send_message(message, inner_1)\n",
    "        response2 = await self.send_message(message, inner_2)\n",
    "        result = f\"Player 1: {response1.content}\\nPlayer 2: {response2.content}\\n\"\n",
    "        judgement = f\"{JUDGE}{result}Who wins?\"\n",
    "        message = TextMessage(content=judgement, source=\"user\")\n",
    "        response = await self._delegate.on_messages([message], ctx.cancellation_token)\n",
    "        return Message(content=result + response.chat_message.content)\n"
   ],
   "id": "bec8d1e4513b3591",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:45:06.907749Z",
     "start_time": "2025-08-31T15:45:06.895958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "runtime = SingleThreadedAgentRuntime()\n",
    "await Player1Agent.register(runtime, \"player1\", lambda: Player1Agent(\"player1\"))\n",
    "await Player2Agent.register(runtime, \"player2\", lambda: Player2Agent(\"player2\"))\n",
    "await RockPaperScissorsAgent.register(runtime, \"rock_paper_scissors\", lambda: RockPaperScissorsAgent(\"rock_paper_scissors\"))\n",
    "runtime.start()"
   ],
   "id": "e8872f11762a3030",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T15:46:56.295041Z",
     "start_time": "2025-08-31T15:45:07.747428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_id = AgentId(\"rock_paper_scissors\", \"default\")\n",
    "message = Message(content=\"go\")\n",
    "response = await runtime.send_message(message, agent_id)\n",
    "print(response.content)"
   ],
   "id": "5682a1ce58ad2ab4",
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCancelledError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m agent_id \u001B[38;5;241m=\u001B[39m AgentId(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrock_paper_scissors\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      2\u001B[0m message \u001B[38;5;241m=\u001B[39m Message(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgo\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m runtime\u001B[38;5;241m.\u001B[39msend_message(message, agent_id)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(response\u001B[38;5;241m.\u001B[39mcontent)\n",
      "File \u001B[1;32mE:\\agentic_ai\\projects\\agents_blank\\.venv\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py:385\u001B[0m, in \u001B[0;36mSingleThreadedAgentRuntime.send_message\u001B[1;34m(self, message, recipient, sender, cancellation_token, message_id)\u001B[0m\n\u001B[0;32m    371\u001B[0m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_queue\u001B[38;5;241m.\u001B[39mput(\n\u001B[0;32m    372\u001B[0m     SendMessageEnvelope(\n\u001B[0;32m    373\u001B[0m         message\u001B[38;5;241m=\u001B[39mmessage,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    380\u001B[0m     )\n\u001B[0;32m    381\u001B[0m )\n\u001B[0;32m    383\u001B[0m cancellation_token\u001B[38;5;241m.\u001B[39mlink_future(future)\n\u001B[1;32m--> 385\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m future\n",
      "\u001B[1;31mCancelledError\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "await runtime.stop()\n",
    "await runtime.close()"
   ],
   "id": "6433aa5b6f1f134e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
